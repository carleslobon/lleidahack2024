{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install numpy\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load initial dataset\n",
    "initial_df = pd.read_csv('./datasets/accions.csv')\n",
    "initial_df.drop(['Usuari', 'Representat'], axis=1, inplace=True)\n",
    "\n",
    "# Remove sessions with less than n actions\n",
    "n = 4\n",
    "session_counts = initial_df.groupby('Sessio').size().reset_index(name='count')\n",
    "sessions_to_keep = session_counts[session_counts['count'] >= n]\n",
    "df = initial_df[initial_df['Sessio'].isin(sessions_to_keep['Sessio'])]\n",
    "\n",
    "# Encode action values\n",
    "df = df.copy()  # If df is a subset of another dataframe, make an explicit copy first\n",
    "df['Accio_Tramit'] = df['Accio'] + '_' + df['Tramit']\n",
    "label_encoder = LabelEncoder()\n",
    "df['action_id'] = label_encoder.fit_transform(df['Accio_Tramit'])\n",
    "df.drop(['Accio', 'Tramit', 'Accio_Tramit'], axis=1, inplace=True)\n",
    "\n",
    "# Store sequences in a dictionary in order\n",
    "df_sorted = df.sort_values(by=['Sessio', 'Data'])\n",
    "session_sequences = {}\n",
    "for session_id, group in df_sorted.groupby('Sessio'):\n",
    "    action_sequence = group['action_id'].tolist()\n",
    "    session_sequences[session_id] = action_sequence\n",
    "\n",
    "num_actions = len(label_encoder.classes_)\n",
    "embedding_dim = 10\n",
    "embedding_map = {}\n",
    "for action_id in range(num_actions):\n",
    "    random_embedding = np.random.randn(embedding_dim).astype(np.float32)\n",
    "    embedding_map[action_id] = random_embedding\n",
    "\n",
    "# Generate sequences embeddings\n",
    "sequence_data = []\n",
    "for session_id, action_sequence in session_sequences.items():\n",
    "    for i in range(len(action_sequence) - 3):\n",
    "        input1 = embedding_map[action_sequence[i]]\n",
    "        input2 = embedding_map[action_sequence[i + 1]]\n",
    "        input3 = embedding_map[action_sequence[i + 2]]\n",
    "        label = embedding_map[action_sequence[i + 3]]\n",
    "        sequence_data.append((input1, input2, input3, label))\n",
    "\n",
    "del initial_df, df_sorted, session_sequences, session_counts, sessions_to_keep, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del initial_df, df_sorted, session_sequences, session_counts, sessions_to_keep, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Input, LSTM, GRU\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = sequence_data[:10]\n",
    "# Convert sequence_data to numpy arrays\n",
    "X = []\n",
    "y = []\n",
    "for seq in aux:\n",
    "    X.append(np.stack(seq[:3]))  # input1, input2, input3\n",
    "    y.append(seq[3])  # label\n",
    "\n",
    "X = np.array(X)  # Shape: (num_samples, 3, num_actions)\n",
    "y = np.array(y)  # Shape: (num_samples, num_actions)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carles/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(3, 10)),\n",
    "    SimpleRNN(32, activation='tanh', input_shape=(3, 10)),  # 3 timesteps, 1 feature\n",
    "    Dense(10, activation='linear')  # Cambia softmax según el tipo de tarea\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(3, 50), return_sequences=False),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(50, activation='linear')  # 50 clases en la salida\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(3, 50)),\n",
    "    GRU(64, activation='tanh', input_shape=(3, 50), return_sequences=False),  # GRU en lugar de SimpleRNN\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(50, activation='linear')  # Cambia softmax según el tipo de tarea\n",
    "])\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7ad122044fa0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/carles/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=4, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Visualizar el rendimiento durante el entrenamiento\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
