{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install numpy\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load initial dataset\n",
    "initial_df = pd.read_csv('./datasets/accions.csv')\n",
    "initial_df.drop(['Usuari', 'Representat'], axis=1, inplace=True)\n",
    "\n",
    "# Remove sessions with less than n actions\n",
    "n = 4\n",
    "session_counts = initial_df.groupby('Sessio').size().reset_index(name='count')\n",
    "sessions_to_keep = session_counts[session_counts['count'] >= n]\n",
    "df = initial_df[initial_df['Sessio'].isin(sessions_to_keep['Sessio'])]\n",
    "\n",
    "# Encode action values\n",
    "df = df.copy()  # If df is a subset of another dataframe, make an explicit copy first\n",
    "df['Accio_Tramit'] = df['Accio'] + '_' + df['Tramit']\n",
    "label_encoder = LabelEncoder()\n",
    "df['action_id'] = label_encoder.fit_transform(df['Accio_Tramit'])\n",
    "df.drop(['Accio', 'Tramit', 'Accio_Tramit'], axis=1, inplace=True)\n",
    "\n",
    "# Store sequences in a dictionary in order\n",
    "df_sorted = df.sort_values(by=['Sessio', 'Data'])\n",
    "session_sequences = {}\n",
    "for session_id, group in df_sorted.groupby('Sessio'):\n",
    "    action_sequence = group['action_id'].tolist()\n",
    "    session_sequences[session_id] = action_sequence\n",
    "\n",
    "num_actions = len(label_encoder.classes_)\n",
    "embedding_dim = 10\n",
    "embedding_map = {}\n",
    "for action_id in range(num_actions):\n",
    "    random_embedding = np.random.randn(embedding_dim).astype(np.float32)\n",
    "    embedding_map[action_id] = random_embedding\n",
    "\n",
    "# Generate sequences embeddings\n",
    "sequence_data = []\n",
    "for session_id, action_sequence in session_sequences.items():\n",
    "    for i in range(len(action_sequence) - 3):\n",
    "        input1 = embedding_map[action_sequence[i]]\n",
    "        input2 = embedding_map[action_sequence[i + 1]]\n",
    "        input3 = embedding_map[action_sequence[i + 2]]\n",
    "        label = embedding_map[action_sequence[i + 3]]\n",
    "        sequence_data.append((input1, input2, input3, label))\n",
    "\n",
    "del initial_df, df_sorted, session_sequences, session_counts, sessions_to_keep, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del initial_df, df_sorted, session_sequences, session_counts, sessions_to_keep, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 20:22:11.170736: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-23 20:22:11.275616: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-23 20:22:11.361545: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732389731.431407   10703 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732389731.453008   10703 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-23 20:22:11.642076: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Input, LSTM, GRU\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = sequence_data\n",
    "# Convert sequence_data to numpy arrays\n",
    "X = []\n",
    "y = []\n",
    "for seq in aux:\n",
    "    X.append(np.stack(seq[:3]))  # input1, input2, input3\n",
    "    y.append(seq[3])  # label\n",
    "\n",
    "X = np.array(X)  # Shape: (num_samples, 3, num_actions)\n",
    "y = np.array(y)  # Shape: (num_samples, num_actions)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gerard/miniconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(3, embedding_dim)),\n",
    "    SimpleRNN(32, activation='tanh', input_shape=(3, embedding_dim)),  # 3 timesteps, 1 feature\n",
    "    Dense(embedding_dim, activation='linear')  # Cambia softmax según el tipo de tarea\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(64, activation='tanh', input_shape=(3, embedding_dim), return_sequences=False),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(embedding_dim, activation='linear')  # 50 clases en la salida\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(3, embedding_dim)),\n",
    "    GRU(64, activation='tanh', input_shape=(3, embedding_dim), return_sequences=False),  # GRU en lugar de SimpleRNN\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(embedding_dim, activation='linear')  # Cambia softmax según el tipo de tarea\n",
    "])\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m367451/367451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 698us/step - accuracy: 0.4350 - loss: 0.6440 - val_accuracy: 0.4436 - val_loss: 0.6191\n",
      "Epoch 2/10\n",
      "\u001b[1m367451/367451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 690us/step - accuracy: 0.4502 - loss: 0.6181 - val_accuracy: 0.4639 - val_loss: 0.6178\n",
      "Epoch 3/10\n",
      "\u001b[1m367451/367451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 693us/step - accuracy: 0.4491 - loss: 0.6160 - val_accuracy: 0.4429 - val_loss: 0.6166\n",
      "Epoch 4/10\n",
      "\u001b[1m367451/367451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 683us/step - accuracy: 0.4507 - loss: 0.6158 - val_accuracy: 0.4538 - val_loss: 0.6139\n",
      "Epoch 5/10\n",
      "\u001b[1m367451/367451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 686us/step - accuracy: 0.4513 - loss: 0.6153 - val_accuracy: 0.4501 - val_loss: 0.6152\n",
      "Epoch 6/10\n",
      "\u001b[1m367451/367451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 685us/step - accuracy: 0.4522 - loss: 0.6157 - val_accuracy: 0.4512 - val_loss: 0.6147\n",
      "Epoch 7/10\n",
      "\u001b[1m367451/367451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 686us/step - accuracy: 0.4539 - loss: 0.6143 - val_accuracy: 0.4572 - val_loss: 0.6145\n",
      "Epoch 8/10\n",
      "\u001b[1m367451/367451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 688us/step - accuracy: 0.4544 - loss: 0.6148 - val_accuracy: 0.4546 - val_loss: 0.6137\n",
      "Epoch 9/10\n",
      "\u001b[1m367451/367451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 688us/step - accuracy: 0.4552 - loss: 0.6138 - val_accuracy: 0.4664 - val_loss: 0.6131\n",
      "Epoch 10/10\n",
      "\u001b[1m367451/367451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 688us/step - accuracy: 0.4558 - loss: 0.6137 - val_accuracy: 0.4659 - val_loss: 0.6127\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=4, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('./models/model_simple_v1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "# Visualizar el rendimiento durante el entrenamiento\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
